torchrun --nproc_per_node 8 --master_port 11112 train.py \
    --llm_model 7B \
    --llama_model_path ./data/weights/ \
    --max_seq_len 512 \
    --batch_size 4 \
    --accum_iter 1 \
    --epochs 20 \
    --warmup_epochs 2 \
    --blr 9e-3 \
    --weight_decay 0.02 \
    --output_dir ./LSRM-seed1/\
    --adapter_dim 12 \
    --adapter_scale 0.1 \
    --prompt_format QCM-A \
    --Delta 0.3 --Lambda 0.85 \
    --seed 1 --emb 320
